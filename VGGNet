  VGGNet (Visual Geometry Group)
  1. ImageNet Large Scale Visual Recognition Challenge
     1) 2014년 
        (1) GoogLeNet & VGGNet
            - GoogLeNet이 우승하였으나 VGG의 구조가 간결하고 사용이 편리하여 더 많이 사용되었다.
        (2) Deep Convolution Networks에 대한 연구이기 때문에 3 x 3으로 필터 사이즈를 고정하고
            깊이의 영향만을 탐구함.
        (3) Filter의 커널 사이즈가 3 x 3으로 결정된 이유는 적정한 깊이를 구하기 위해서다. 더 큰 사이즈의 커널을 사용하면 
            이미지의 사이즈가 빠르게 축소되어 깊이를 충분하게 확보하기 어려워진다.
            
     2) 구조
        (1) 3 x 3 filter 사용
            - Input Image 10 x 10 
            - 7 x 7 Filter x 1 = (10 - 7)1 + 1 = 4 
            - 3 x 3 Filter x 3 = (10 - 3) + 1 = 8 -> (8 - 3) + 1 = 6 -> (6 - 3) + 1 = 4 
            : 7 x 7 1time과 3 x 3 3time은 동일한 FeatureMap Size를 얻을 수 있다. 
            1) 차이점
               (1) 결정 함수의 비선형성 증가 
                   - 각 Conv연산에는 ReLU가 포함된다. 따라서 1-Layer 7x7 필터의 경우는 하나의 활성화함수가 사용되는 반면에
                     3-Layer 3 x 3은 세개의 활성화함수가 사용된다. 즉, 활성화 함수가 많아 짐에 따라 모델의 특징 식별성이 증가한다.
               (2) 학습 파라미터 수의 감소
                   - 가중치는 필터의 크기에 해당한다. 1-Layer 7x7의 파라미터의 갯수는 7x7 = 49이며 3-Layer 3x3의 파라미터의 갯수는 
                     3 x 3 x 3 = 27이다. 즉, 학습에 필요한 파라미터의 갯수가 줄어들어 연산의 속도가 빠르다. 
                     
        (2) 모델 학습 
            1) 최적화 알고리즘 (논문 제시)
               (1) Optimizing multinomial logistic regression
               (2) mini-batch gradient descent
               (3) Momentum(0.9)
               (4) Weight Decay(L2 Norm)
               (5) Dropout(0.5)
               (6) Learning rate 0.01로 초기화 후 서서히 줄임
               
            2) 가중치 초기화
               - 딥러닝에서 가중치 초기화는 학습 속도 및 안정성에 큰 영향을 줄 수 있다. 따라서 어떤 방식으로 초기화할 것인지는 
                 중요한 요소이다.
                 1) 상대적으로 얕은 11-Layer(A) 네트워크를 우선적으로 학습한다. 이때 가중치는 정규분포를 따르도록 임의의 값으로 초기화한다.
                 2) 어느 정도의 학습이 된다면 입력층 부분의 4개의 층과 마지막 3개의 FC의 weight를 학습할 네트워크 초기값으로 사용한다. 
                 :: 이후 무작윈 초기화 절차를 이용하여 사전 훈련이 없이 가중치를 초기화 할 수 있다는 것을 밝힘.
                 
        (3) Conv 16 Layers - Step
            1. 1단계 
               1) Conv2d
               2) BatchNorm2d
               3) ReLU
               4) Conv2d
               5) BatchNorm2d
               6) ReLU
               7) Maxpool2d
            
            2. 2단계 
               1) Conv2d
               2) BatchNorm2d
               3) ReLU
               4) Conv2d
               5) BatchNorm2d
               6) ReLU
               7) Maxpool2d
            
            3. 3단계 
               1) Conv2d
               2) BatchNorm2d
               3) ReLU
               4) Conv2d
               5) BatchNorm2d
               6) ReLU
               7) Conv2d
               8) BatchNorm2d
               9) ReLU
              10) Maxpool2d
            
            4. 4단계 
               1) Conv2d
               2) BatchNorm2d
               3) ReLU
               4) Conv2d
               5) BatchNorm2d
               6) ReLU
               7) Conv2d
               8) BatchNorm2d
               9) ReLU
              10) Maxpool2d
              
            5. 5단계 
               1) Conv2d
               2) BatchNorm2d
               3) ReLU
               4) Conv2d
               5) BatchNorm2d
               6) ReLU
               7) Conv2d
               8) BatchNorm2d
               9) ReLU
              10) Maxpool2d
              
            6. 6단계 
               1) AdaptiveAvgPool2d
               2) Linear
               3) ReLU
               4) Dropout
               6) Linear
               7) ReLU
               8) Dropout
               9) Linear
               
        (4) Conv 16 Layers(Zero Padding : 1, Stride : 1, 1~15 ReLU Used, Maxpool 2 x 2-s2)
            0) Input Image (224 x 224 x 3) RGB File
            1)  1-1 Conv3-64+ReLU: 64개의 (3 x 3 x 3) 사용, (224 + 2 - 3)/1 + 1 = 224, Result (224 x 224 x 64) 
            2)  1-2 Conv3-64+ReLU: 64개의 (3 X 3 X 64) 사용, (224 + 2 - 3)/1 + 1 = 224 & MaxPool(2x2-s2) = 112, Result(112 x 112 x 64)
            3)  2-1 Conv3-128+ReLU: 128개의 (3 x 3 x 64) 사용, (112 + 2 -3)/1 + 1 = 112, Result (112 x 112 x 128)
            4)  2-2 Conv3-128+ReLU: 128개의 (3 x 3 x 128) 사용, (112 + 2 - 3)/1 + 1 =112 & Maxpool(2x2-s2) = 56, Result(56 x 56 x 128)
            5)  3-1 Conv3-256+ReLU: 256개의 (3 x 3 x 128) 사용, (56 + 2 - 3)/1 + 1 = 56, Result (56 x 56 x 256)
            6)  3-2 Conv3-256+ReLU: 256개의 (3 x 3 x 256) 사용, (56 + 2 - 3)/1 + 1 = 56, Result (56 x 56 x 256)
            7)  3-3 Conv3-256+ReLU: 256개의 (3 x 3 x 256) 사용, (56 + 2 - 3)/1 + 1 = 56 & Maxpool(2x2-s2) = 28, Result (28 x 28 x 256)
            8)  4-1 Conv3-512+ReLU: 512개의 (3 x 3 x 512) 사용, (28 + 2 - 3)/1 + 1 = 28, Result (28 x 28 x 512)
            9)  4-2 Conv3-512+ReLU: 512개의 (3 x 3 x 512) 사용, (28 + 2 - 3)/1 + 1 = 28, Result (28 x 28 x 512)
            10) 4-3 Conv3-512+ReLU: 512개의 (3 x 3 x 512) 사용, (28 + 2 - 3)/1 + 1 = 28 & Maxpool(2x2-s2) = 14, Result (14 x 14 x 512)
            11) 5-1 Conv3-512+ReLU: 512개의 (3 x 3 x 512) 사용, (14 + 2 -3)/1 + 1 = 14, Result (14 x 14 x 512) 
            12) 5-2 Conv3-512+ReLU: 512개의 (3 x 3 x 512) 사용, (14 + 2 -3)/1 + 1 = 14, Result (14 x 14 x 512)
            13) 5-3 Conv3-512+ReLU: 512개의 (3 x 3 x 512) 사용, (14 + 2 -3)/1 + 1 = 14& Maxpool (2x2-s2) = 7, Result (7 x 7 x 512)
            14) 6-1 FC-4096+ReLU: (7 x 7 x 512)의 Feature Map을 Flatten = 7 x 7 x 512 = 25,088개의 뉴런과 4096의 뉴런을 Fully Connected, 훈련시 Dropout
            15) 6-2 FC-4096+ReLU: 4096개의 뉴런으로 구성되어 14) 6-1과 Fully Connected 
            16) 6-3 FC-1000: 1000개의 뉴런으로 구성되어 15) 6-2와 Fully Connected 
                             -> Softmax를 통하여 Classification 1,000개로 구분된다. 
            
         
          
         
               
