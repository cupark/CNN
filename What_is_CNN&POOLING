==============================================================================================================================
What is CNN (Convolution Nerual Network)

 합성곱 연산이 들어가는 Neural Network를 의미한다. 
 최초 CNN을 고안할때 고양이의 뇌의 사물인식 반을을 토대로 개발되었다.
 고양이가 어떠한 물체를 인지할 때 보는 대상에 따라 반응하는 뇌의 위치가 달라졌다는것에 아이디어를 얻었다.
 이에 따라 CNN의 핵심 아이디어는 주어진 Image의 전체를 보는것이 아니라 부분을 보는것이다.
  **'Image의 부분 = Filter** 의 개념을 숙지해야한다.
==============================================================================================================================

==============================================================================================================================
What is Filter

 위에 언급된 Image의 부분 즉, Filter란 주어진 이미지의 전체를 대상으로한 부분에서 특정한 하나의 값을 얻어 낼 때 사용된다.
 단, 하나의 값을 얻어낸다는 의미가 Pooling을 뜻하는것은 아니다. 
 예1) 
  * N : Image Total Size = 7 x 7
  * F : Filter Size = 3 x 3, 9개의 Parameter = x -> weight * x + bias = y
                                          ReLU(weight * x + b) = y 등의 연산으로 하나의 실수값으로 출력이 가능하다.
  * S : Stride = 1
  * Padding 
  
  위의 4가지를 알고 있다면 Output Size를 구할 수 있다. 
  ** Output Size : K = (N-F)/S + 1  = (7-3)/1 +1 = 5 (Convolution Layer) 단, 예를 들어 K의 값이 정수가 아닌경우는 제외한다. 
  예2) N = 7, F= 3, S = 3 인 경우 (7-3)/3 = 1.3333 => 해당 데이터값을 할당 하지 않도록 한다. 
==============================================================================================================================

==============================================================================================================================
 What is Convolution
 
  결국 Filter 하나당 Activation이 하나 주어지면 이에 따른 Convolution Layer를 얻을 수 있다. 
  따라서 Filter가 달라지면 이에 따라 Activation을 다르게 줄 수 있고 또다른 Convolution Layer를 얻을 수 있는것이다. 
  예1)에 따라 N = 7 x 7, F = 3 x 3, S = 1인 경우에 Filter로 부터 5 x 5인 Convolution Layer 1개를 얻을 수 있다.
  여기서 Filter를 6개 사용한다면, 5 x 5인 Convolution Layer를 6개 얻을 수 있다. 
  이를 하나로 합치면 5 x 5 x 6의 Activation Map을 얻을 수 있다. 
  위의 모든 과정을 합성곱(Convolution)이라고 부른다.
==============================================================================================================================
    
==============================================================================================================================
 What is Padding 
  기본적으로 Convolution Layer의 사이즈 K는 원본 이미지의 사이즈 N보다 작거나 같다. (F,S가 1보다 크거나 같기 때문이다.)
   - K = (N-F)/S + 1 
  Padding을 사용하는 궁극적인 이유는 Filter를 사용함에 따른 어쩔 수 없는 원본 이미지의 정보 손실을 최소화 하기 위함이다. 
  예3) 원본의 이미지 사이즈(N)가 7 x 7, 필터의 사이즈(F)가 3 x 3, 스트라이드의 값이 1인 경우 5 x 5의 사이즈를 갖는 Convolution Layer를 얻을 수 있다.
       이때 각 Pixel의 RGB값을 무시하고 1차원 벡터로 전환하면 N의 49차원 데이터가 K의 25차원 데이터로 손실이 발생하게 된다. 
  위 예3)의 데이터(원본 이미지의 정보) 손실은 불가피하다. 따라서 (N-F)/S + 1 = K에서 K의 결과가 N = K로 맞추기 위하여 Padding을 사용한다.
  즉, 원본의 차원을 유지하기 위함이다. 
   * Padding을 적용한 공식 : ((N+2P)-F)/S +1 = K 
   예4) N = 7, F = 3, S =1 일때, K가 7이 되게 하는 P의 값은 (4 + 2P) + 1 = 7 => P = 1이 나온다. 
   
  P의 위치에 있는 데이터가 합성곱 과정에서 원치 않는 노이즈를 만들게 되지만 차원의 손실을 발생시키는것 보다 낫기 떄문에 노이즈와 차원손실을 서로 Trade Off 해준다. 
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
